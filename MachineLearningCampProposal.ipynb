{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MachineLearningCampProposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a proposal project to attend Machine Learning Camp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My goal is to add the idea of section classification to existing paper “Convolutional Neural Networks for Sentence Classification. Yoon Kim. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, Doha, Qatar.” and apply it to the dataset of the particular type of document, along with training document specific Word2Vec and scale it up. The input will be a document which can be of any architecture within and the desired output is a very clean and structured information which easy to index and search.\n",
    "The details are in the following sections:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification Model for Unstructured Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of my project is to classify any type of document which has certain format/pattern associated with a particular genre of the document. \n",
    "\n",
    "We have seen a lot of document classifiers which can segregate multiple types of documents based on the content when trained with abundant data and if, appropriate classes are defined, can identify the types of document but there are documents which have multiple segments inside them, the sections within are completely explicit from each other but together make the whole document meaningful as well as relevant. \n",
    "\n",
    "For this, a Resume is a perfect example. It consists of different sections which are completely different but collaboratively make a perfect meaningful document. The main challenge with a resume is that it is highly ambiguous and unstructured which makes it a complex problem, if this problem can be fully tackled and the data can be converted into a perfectly structured format, then it can open doors to more future projects for documents of this type.The training dataset of each and every type of document will be separate(Resumes/Research Papers/Other Documents) \n",
    "I have already reached almost halfway through the project and classified whatever could be retrieved using heuristics and NLP but the result is not satisfactory as rule-based parsing is not robust. Now to attain a good accuracy, I need to apply Deep Learning for Text Classification inside the segments of the document so that each sentence can be mapped into its appropriate section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason behind applying Deep Learning to this problem is, the high amount of ambiguity that can be faced. As there is no specified format of a Resume, each and every resume is unique within itself, from formatting to context, everything is very different, apart from the certain type of sections which are sometimes common but not always in the same sequence. With Deep Learning, I aim to achieve the accuracy which has not been met before by building a Text Classification system for this that will certainly be a breakthrough.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application in Real World "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using this on research papers we can make research more accessible to individuals. There are a lot of research papers which go unread because there is no single repository where we can find what we are looking for or even if there is, the accessibility is difficult. With the use of this idea, we can have a repository and make searching easier and faster in all research papers as all the sections can be separated out and the search space can be minimized to the initial sections of the document which contain the summary along with the special keywords.\n",
    "\n",
    "After achieving this I would like to make every module of this work as a micro-service, modular and replaceable i.e. If there is more research on a slightly different type of document and there is a need to make it specific to that particular type of document, it'll be very easy to achieve that. This can be done with Language Specific Research Papers, various type of Official Documents etcetera. Scaling this to an entire level where it acts as a service and specifically in the case of resume this can become a pool of individuals actively seeking a job and all they have to do is upload their resume and all the information gets classified automatically into its sections, searching and evaluation becomes so easy and dynamic. With this, we can achieve faster and better results in all types of document searches. If a person wants to find a particular keyword in all the documents, all they have to do is search that specific section in which the keyword occurs and wouldn't have to iterate over the entire document. Indexing is also a major advantage in this if we want to list together all documents according to a particular attribute in a document that will become easier and the time complexity would decrease drastically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future work can possibly involve the same heuristic over documents which are in the form of images, retrieving text from those images and classifying the sections of an image and working out the whole heuristic on the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R. Socher, J. Pennington, E. Huang, A. Ng, C. Manning. 2011. Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions. In Proceedings of EMNLP 2011.\n",
    "\n",
    "Ye Zhang, Byron Wallace, 2015. A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification.\n",
    "\n",
    "B. Yang, C. Cardie. 2014. Context-aware Learning for Sentence-level Sentiment Analysis with Posterior Regularization. In Proceedings of ACL 2014.\n",
    "\n",
    "W. Yih, X. He, C. Meek. 2014. Semantic Parsing for Single-Relation Question Answering. In Proceed- ings of ACL 2014.\n",
    "\n",
    "Y. LeCun, L. Bottou, Y. Bengio, P. Haffner. 1998. Gradient-based learning applied to document recog- nition. In Proceedings of the IEEE, 86(11):2278– 2324, November.\n",
    "\n",
    "N. Kalchbrenner, E. Grefenstette, P. Blunsom. 2014. A Convolutional Neural Network for Modelling Sen- tences. In Proceedings of ACL 2014.\n",
    "\n",
    "M. Hu, B. Liu. 2004. Mining and Summarizing Cus-tomer Reviews. In Proceedings of ACM SIGKDD 2004."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
